{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Aug 19, 2016\n",
    "\n",
    "@author: rbhat\n",
    "'''\n",
    "import random\n",
    "import numpy\n",
    "from keras.models import Model\n",
    "from keras.layers import Convolution2D, Dense, Flatten, Input, merge\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from theano import printing\n",
    "from theano.gradient import disconnected_grad\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size=None, number_of_actions=1, epsilon=0.1, mbsz=32, discount=0.9, memory=50,\n",
    "                 save_name='basic', save_freq=10):\n",
    "        self.state_size = state_size\n",
    "        self.number_of_actions = number_of_actions\n",
    "        self.epsilon = epsilon\n",
    "        self.mbsz = mbsz\n",
    "        self.discount = discount\n",
    "        self.memory = memory\n",
    "        self.save_name = save_name\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.experience = []\n",
    "        self.i = 1\n",
    "        self.save_freq = save_freq\n",
    "        self.build_functions()\n",
    "\n",
    "    def build_model(self):\n",
    "        S = Input(shape=self.state_size)\n",
    "        h = Convolution2D(16, 8, 8, subsample=(4, 4), border_mode='same', activation='relu')(S)\n",
    "        h = Convolution2D(32, 4, 4, subsample=(2, 2), border_mode='same', activation='relu')(h)\n",
    "        h = Flatten()(h)\n",
    "        h = Dense(256, activation='relu')(h)\n",
    "        V = Dense(self.number_of_actions)(h)\n",
    "        self.model = Model(S, V)\n",
    "        try:\n",
    "            self.model.load_weights('{}.h5'.format(self.save_name))\n",
    "            print \"loading from {}.h5\".format(self.save_name)\n",
    "        except:\n",
    "            print \"Training a new model\"\n",
    "\n",
    "\n",
    "    def build_functions(self):\n",
    "        S = Input(shape=self.state_size)\n",
    "        NS = Input(shape=self.state_size)\n",
    "        A = Input(shape=(1,), dtype='int32')\n",
    "        R = Input(shape=(1,), dtype='float32')\n",
    "        T = Input(shape=(1,), dtype='int32')\n",
    "        self.build_model()\n",
    "        self.value_fn = K.function([S], self.model(S))\n",
    "\n",
    "        VS = self.model(S)\n",
    "        VNS = disconnected_grad(self.model(NS))\n",
    "        future_value = (1-T) * VNS.max(axis=1, keepdims=True)\n",
    "        discounted_future_value = self.discount * future_value\n",
    "        target = R + discounted_future_value\n",
    "        cost = ((VS[:, A] - target)**2).mean()\n",
    "        opt = RMSprop(0.0001)\n",
    "        params = self.model.trainable_weights\n",
    "        updates = opt.get_updates(params, [], cost)\n",
    "        self.train_fn = K.function([S, NS, A, R, T], cost, updates=updates)\n",
    "\n",
    "    def new_episode(self):\n",
    "        self.states.append([])\n",
    "        self.actions.append([])\n",
    "        self.rewards.append([])\n",
    "        self.states = self.states[-self.memory:]\n",
    "        self.actions = self.actions[-self.memory:]\n",
    "        self.rewards = self.rewards[-self.memory:]\n",
    "        self.i += 1\n",
    "        if self.i % self.save_freq == 0:\n",
    "            self.model.save_weights('{}.h5'.format(self.save_name), True)\n",
    "\n",
    "    def end_episode(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, state):\n",
    "        self.states[-1].append(state)\n",
    "        values = self.value_fn([state[None, :]])\n",
    "        if numpy.random.random() < self.epsilon:\n",
    "            action = numpy.random.randint(self.number_of_actions)\n",
    "        else:\n",
    "            action = values.argmax()\n",
    "        self.actions[-1].append(action)\n",
    "        return action, values\n",
    "\n",
    "    def observe(self, reward):\n",
    "        self.rewards[-1].append(reward)\n",
    "        return self.iterate()\n",
    "\n",
    "    def iterate(self):\n",
    "        N = len(self.states)\n",
    "        S = numpy.zeros((self.mbsz,) + self.state_size)\n",
    "        NS = numpy.zeros((self.mbsz,) + self.state_size)\n",
    "        A = numpy.zeros((self.mbsz, 1), dtype=numpy.int32)\n",
    "        R = numpy.zeros((self.mbsz, 1), dtype=numpy.float32)\n",
    "        T = numpy.zeros((self.mbsz, 1), dtype=numpy.int32)\n",
    "        for i in xrange(self.mbsz):\n",
    "            episode = random.randint(max(0, N-50), N-1)\n",
    "            num_frames = len(self.states[episode])\n",
    "            frame = random.randint(0, num_frames-1)\n",
    "            S[i] = self.states[episode][frame]\n",
    "            T[i] = 1 if frame == num_frames - 1 else 0\n",
    "            if frame < num_frames - 1:\n",
    "                NS[i] = self.states[episode][frame+1]\n",
    "            A[i] = self.actions[episode][frame]\n",
    "            R[i] = self.rewards[episode][frame]\n",
    "        cost = self.train_fn([S, NS, A, R, T])\n",
    "        return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: Pendulum-v0\n",
      "[2016-08-19 12:38:10,647] Making new env: Pendulum-v0\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Input 0 is incompatible with layer convolution2d_5: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-235c51169942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mnb_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_actions\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnb_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#number_of_actions= env.action_space.n,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-33d715421265>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, state_size, number_of_actions, epsilon, mbsz, discount, memory, save_name, save_freq)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-33d715421265>\u001b[0m in \u001b[0;36mbuild_functions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-33d715421265>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;31m# raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;31m# with the input_spec specified in the layer constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# collect input shapes to build layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m                                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m                                         str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Input 0 is incompatible with layer convolution2d_5: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Aug 19, 2016\n",
    "\n",
    "@author: rbhat\n",
    "'''\n",
    "import sys\n",
    "import gym\n",
    "#from dqn1 import Agent\n",
    "\n",
    "num_episodes = 20\n",
    "\n",
    "env_name = \"Pendulum-v0\" #\"MsPacman-v0\"\n",
    "env = gym.make(env_name)\n",
    "\n",
    "nb_actions = env.action_space.shape[0]\n",
    "\n",
    "agent = Agent(state_size=env.observation_space.shape, number_of_actions= nb_actions, save_name=env_name) #number_of_actions= env.action_space.n,\n",
    "\n",
    "for e in xrange(num_episodes):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    agent.new_episode()\n",
    "    total_cost = 0.0\n",
    "    total_reward = 0.0\n",
    "    frame = 0\n",
    "    while not done:\n",
    "        frame += 1\n",
    "        env.render()\n",
    "        action, values = agent.act(observation)\n",
    "        #action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_cost += agent.observe(reward)\n",
    "        total_reward += reward\n",
    "    print \"total reward\", total_reward\n",
    "    print \"mean cost\", total_cost/frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
