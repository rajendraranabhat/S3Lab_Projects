{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Self-Taught Learning and Unsupervised Feature Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n",
      "ERROR:theano.sandbox.cuda:nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports done\n",
      "<type 'dict'>\n",
      "(12180, 13)\n",
      "[[ 343.33881535  292.94608369  317.56346931 ...,    0.            0.            2.        ]\n",
      " [ 229.55690517  183.19172676    0.         ...,    0.            0.            2.        ]\n",
      " [ 106.98249046   79.89465389   60.93378272 ...,   50.91543646\n",
      "    44.87156581    1.        ]\n",
      " ..., \n",
      " [ 232.28249497  135.43054     200.91859872 ...,  187.78214091\n",
      "   191.41443704    0.        ]\n",
      " [ 239.19601078  206.37272444  174.6964434  ...,  297.67230497\n",
      "   202.62736538    0.        ]\n",
      " [ 277.38010202  209.01016123  277.00169283 ...,  146.70298371\n",
      "   309.63963308    0.        ]]\n",
      "Example:\n",
      "[ 229.55690517  183.19172676    0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.            0.\n",
      "    2.        ]\n",
      "(12180, 12) (12180,)\n",
      "(12180,)\n",
      "(8526, 12) (8526,) (3654, 12) (3654,)\n",
      "(8526, 12, 1) (3654, 12, 1)\n",
      "(8526, 'train samples')\n",
      "(3654, 'test samples')\n",
      "Sets made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as scpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.optimize as opt\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import theano.tensor as T\n",
    "from theano import function\n",
    "from theano import shared\n",
    "import theano\n",
    "from theano.tensor.signal import downsample\n",
    "from theano.tensor.nnet import conv\n",
    "\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Layer, Reshape, Merge #,AutoEncoder\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D,Convolution1D,MaxPooling1D,UpSampling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adadelta\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "#import keras.utils.visualize_util as vutil #Pydot issues\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.regularizers import l1, l2, l1l2, activity_l2, activity_l1\n",
    "#import keras.layers.containers as containers  #No module named containers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.regularizers import ActivityRegularizer\n",
    "from keras import backend as K\n",
    "#import keras.utils.visualize_util as vutil\n",
    "from keras.models import model_from_json\n",
    "#from keras.utils.visualize_util import plot, to_graph\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "np.set_printoptions(suppress=True)  #Supress exponent of the number 2e-2 == 0.02\n",
    "\n",
    "import load_MNIST\n",
    "import numpy as np\n",
    "import sparse_autoencoder\n",
    "import scipy.optimize\n",
    "import display_network\n",
    "import softmax\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"All imports done\")\n",
    "\n",
    "\n",
    "#Ref: http://deeplearning.net/, https://www.kaggle.com/wiki/Tutorials etc..\n",
    "\n",
    "#caso_I.mat, caso_II.mat, caso_III.mat, caso_base.mat, consumer_data.xlsx\n",
    "\n",
    "#print(os.getcwd() + \"\\n\")\n",
    "#print os.listdir(os.getcwd())\n",
    "dataSmartGrid = scpy.loadmat('/home/rbhat/Workspace/S3Lab_Projects/Deep-SmartGrid/demcliMat.mat')\n",
    "print type(dataSmartGrid)\n",
    "\n",
    "data = dataSmartGrid['demcliMat']\n",
    "print data.shape\n",
    "print data\n",
    "print(\"Example:\")\n",
    "print data[1]\n",
    "\n",
    "np.unique(data[:,-1:])\n",
    "\n",
    "X = data[:,0:-1]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print X.shape, Y.shape\n",
    "\n",
    "#print X.shape\n",
    "Y1 = Y\n",
    "Y1[Y1==2] = 1\n",
    "print Y1.shape\n",
    "\n",
    "np.unique(Y1)\n",
    "\n",
    "#print data[0:5,:]\n",
    "#print data[0:5,0:-1]\n",
    "#print data[0:5,-1]\n",
    "\n",
    "\n",
    "#print X\n",
    "#print Y\n",
    "#Splitting data into train and testing. 70% Training and 30% Testing..\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y1, test_size=0.3, random_state=4)\n",
    "\n",
    "print X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "#print numpy.unique(Y_test)\n",
    "\n",
    "X_train_1 = X_train.reshape(8526,12,1)\n",
    "X_test_1 = X_test.reshape(3654,12,1)\n",
    "\n",
    "print X_train_1.shape, X_test_1.shape \n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 2)\n",
    "Y_test = np_utils.to_categorical(y_test, 2)\n",
    "\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')\n",
    "\n",
    "print(\"Sets made\")\n",
    "\n",
    "rms = RMSprop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# examples in unlabeled set: 4262\n",
      "\n",
      "# examples in supervised training set: 4262\n",
      "\n",
      "# examples in supervised testing set: 3654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 12\n",
    "num_labels = 2\n",
    "hidden_size = 196\n",
    "\n",
    "tot_iter = 400\n",
    "\n",
    "sparsity_param = 0.1  # desired average activation of the hidden units.\n",
    "lambda_ = 3e-3  # weight decay parameter\n",
    "beta = 3  # weight of sparsity penalty term\n",
    "\n",
    "#Unlabelled Data\n",
    "\n",
    "X_train_new = np.transpose(X_train)\n",
    "X_test_new  = np.transpose(X_test)\n",
    "\n",
    "unlabeled_data = X_train_new[ : , 4263:8525]\n",
    "\n",
    "\n",
    "#Labelled Data\n",
    "train_data = X_train_new[ : , 0:4262]\n",
    "train_labels = y_train[0:4262]\n",
    "\n",
    "test_data = X_test_new\n",
    "test_labels = y_test\n",
    "\n",
    "print '# examples in unlabeled set: {0:d}\\n'.format(unlabeled_data.shape[1])\n",
    "print '# examples in supervised training set: {0:d}\\n'.format(train_data.shape[1])\n",
    "print '# examples in supervised testing set: {0:d}\\n'.format(test_data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    nfev: 458\n",
      "     fun: 366285.4368353716\n",
      "       x: array([-1.59064336, -1.49649353, -1.11331628, ...,  4.62476761,\n",
      "        4.90832128,  5.00598477])\n",
      " message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     jac: array([-0.00477193, -0.00448948, -0.00333995, ..., -0.04583577,\n",
      "       -0.04047647, -0.03576004])\n",
      "     nit: 349\n"
     ]
    }
   ],
   "source": [
    "## ======================================================================\n",
    "#  STEP 2: Train the sparse autoencoder\n",
    "#  This trains the sparse autoencoder on the unlabeled training\n",
    "#  images.\n",
    "\n",
    "#  Randomly initialize the parameters\n",
    "theta = sparse_autoencoder.initialize(hidden_size, input_size)\n",
    "\n",
    "J = lambda x: sparse_autoencoder.sparse_autoencoder_cost(x, input_size, hidden_size,\n",
    "                                                         lambda_, sparsity_param,\n",
    "                                                         beta, unlabeled_data)\n",
    "\n",
    "options_ = {'maxiter': tot_iter, 'disp': True} #Was 400\n",
    "result = scipy.optimize.minimize(J, theta, method='L-BFGS-B', jac=True, options=options_)\n",
    "opt_theta = result.x\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the weights\n",
    "W1 = opt_theta[0:hidden_size * input_size].reshape(hidden_size, input_size).transpose()\n",
    "#display_network.display_network(W1,filename='STL_Weights.png')\n",
    "\n",
    "##======================================================================\n",
    "## STEP 3: Extract Features from the Supervised Dataset\n",
    "#\n",
    "#  Train on labeled set using unlabeled weights.\n",
    "#  \n",
    "\n",
    "train_features = sparse_autoencoder.sparse_autoencoder(opt_theta, hidden_size,\n",
    "                                                       input_size, train_data)\n",
    "\n",
    "test_features = sparse_autoencoder.sparse_autoencoder(opt_theta, hidden_size,\n",
    "                                                      input_size, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    nfev: 251\n",
      "     fun: 685.75929010055222\n",
      "       x: array([-0.16397887,  0.50972857, -0.16056797, -0.15827942, -0.53709237,\n",
      "       -0.14531182, -0.1637121 ,  0.46070658, -0.15075828, -0.16090846,\n",
      "       -0.15859434, -0.16073675, -0.74232003, -0.15994617, -0.09761587,\n",
      "       -0.96985818, -0.15539252, -0.13866354, -5.01936221, -0.38713982,\n",
      "        0.03338288, -0.16291524,  0.49307587,  0.00571932,  0.2434708 ,\n",
      "       -0.51527062,  0.17560285, -0.156486  , -0.15210426, -0.12044086,\n",
      "        0.01942299, -0.14826068, -0.16240654, -0.15822431, -0.64298973,\n",
      "        0.10954248, -0.26912841,  0.02851993,  0.16709771,  0.42096949,\n",
      "       -0.1589995 , -0.76371318, -0.15846923, -0.15713617,  0.48401345,\n",
      "       -0.15205344, -0.15806945, -0.17274667,  0.60707117, -0.15676691,\n",
      "       -0.15432164, -0.15362029, -3.45014656, -0.39064296,  0.3465896 ,\n",
      "        0.22995386,  0.04364837,  0.32409825, -0.09773282, -0.15933188,\n",
      "       -0.44966599, -0.15954318,  0.11501755, -0.90972273, -0.15053764,\n",
      "       -0.15349496,  0.05845098,  0.51775303,  0.03272951,  0.1279792 ,\n",
      "       -0.58269666, -0.59113174, -0.15947602,  0.00412898,  0.14445271,\n",
      "        0.79294262,  0.14222076,  0.32146335, -0.22569893, -0.15126969,\n",
      "        0.62642739, -0.15607194, -0.60093427, -1.85518678, -0.16674343,\n",
      "       -0.03984861,  0.33351393, -0.15705169, -0.15411129,  0.02603278,\n",
      "        0.48725471, -0.16268492,  0.09289295, -0.15770449, -0.17977618,\n",
      "       -0.15998943, -0.21391659,  0.07780967, -0.15862227, -0.1987271 ,\n",
      "        0.1980882 ,  0.69303721,  1.26109164,  0.51645457, -0.75513098,\n",
      "       -0.15529048,  0.01589438, -0.15980556,  0.23875291,  0.87688913,\n",
      "        0.11449602,  0.10094758,  0.70325563, -0.15244369, -0.15574128,\n",
      "       -0.16090624,  0.04995828, -0.66363075,  0.24334464,  0.133592  ,\n",
      "        0.23554391, -0.31815292,  0.73035984, -0.1553421 ,  0.45221635,\n",
      "        0.42192742,  0.97389524, -0.39157193, -0.16160573, -0.15180996,\n",
      "       -0.15431377, -0.15694162,  0.5036088 , -0.06274273, -0.1570218 ,\n",
      "       -0.43874161,  0.31363621, -0.13429632,  0.25825789, -0.58030432,\n",
      "       -0.15975892, -0.14367665, -0.16168382,  0.07190941, -0.1572367 ,\n",
      "       -0.15169621, -0.15537577, -0.67166901, -0.06657142,  0.70003198,\n",
      "       -0.23086352, -0.0209582 ,  0.4886361 , -0.76579962,  0.08393057,\n",
      "       -0.15514125,  0.08071348,  0.81835902,  0.11560243, -0.14843072,\n",
      "        0.01885047,  0.13916253, -0.17826978,  0.33015536,  0.01394141,\n",
      "        0.22775209, -0.15186187,  0.08162762,  1.42605084, -0.15694932,\n",
      "        0.34348178,  0.18486828,  0.53563148,  0.67697805, -0.11718864,\n",
      "        0.40314002, -0.15836995, -0.30340393, -0.16873798,  0.35928676,\n",
      "        0.68416296,  0.07180421, -0.15367723,  0.32690385,  0.49630312,\n",
      "        0.02403517,  0.52086752, -0.07154979, -0.1639342 , -0.2445681 ,\n",
      "       -0.03187757, -0.15580166, -0.1593292 , -0.12552579, -0.43402518,\n",
      "       -0.07558641,  0.1685695 , -0.51504034,  0.16114669,  0.16345058,\n",
      "        0.54240447,  0.15889588,  0.14970884, -0.46952839,  0.15546427,\n",
      "        0.15886583,  0.16211841,  0.14912625,  0.74884378,  0.1502784 ,\n",
      "        0.0959751 ,  0.97408297,  0.15645394,  0.14012618,  5.02531057,\n",
      "        0.38296094, -0.03219487,  0.15732372, -0.48318611,  0.00776367,\n",
      "       -0.23793345,  0.51184896, -0.17069053,  0.17166792,  0.15318422,\n",
      "        0.1284276 , -0.03145433,  0.15968993,  0.1514564 ,  0.15735927,\n",
      "        0.63959683, -0.1121946 ,  0.27735895, -0.03259628, -0.16526831,\n",
      "       -0.42062911,  0.14955397,  0.76240985,  0.15023738,  0.15723858,\n",
      "       -0.49036937,  0.15873784,  0.15788368,  0.17937457, -0.60411076,\n",
      "        0.15933553,  0.1477851 ,  0.1604438 ,  3.44001685,  0.3909654 ,\n",
      "       -0.34295434, -0.23900545, -0.04874746, -0.31800328,  0.10411575,\n",
      "        0.1558609 ,  0.44613663,  0.15621889, -0.10862775,  0.90765633,\n",
      "        0.16566286,  0.15588439, -0.04455147, -0.50700542, -0.02215319,\n",
      "       -0.13075631,  0.59217584,  0.58192024,  0.15933881, -0.00606908,\n",
      "       -0.15237342, -0.79780825, -0.15683585, -0.3140827 ,  0.22890366,\n",
      "        0.16428617, -0.61844606,  0.15633742,  0.59455318,  1.85168207,\n",
      "        0.15320095,  0.04013891, -0.32329735,  0.16361424,  0.16304434,\n",
      "       -0.01594465, -0.49119255,  0.15410871, -0.09419887,  0.16956552,\n",
      "        0.17706143,  0.1599195 ,  0.21041666, -0.07372421,  0.15312093,\n",
      "        0.20419855, -0.20255926, -0.68918116, -1.25774497, -0.51622612,\n",
      "        0.74686509,  0.15481089, -0.01612575,  0.15925645, -0.23448868,\n",
      "       -0.8723663 , -0.10408753, -0.10646866, -0.71368359,  0.16112419,\n",
      "        0.15057225,  0.16221869, -0.04360648,  0.66833248, -0.24803142,\n",
      "       -0.12969608, -0.23453551,  0.31737303, -0.73088317,  0.14913865,\n",
      "       -0.46931889, -0.4177928 , -0.9646824 ,  0.40716552,  0.15496798,\n",
      "        0.15260918,  0.15639081,  0.15449874, -0.5041428 ,  0.05182292,\n",
      "        0.15394962,  0.43650389, -0.31967299,  0.11362976, -0.24022263,\n",
      "        0.58485609,  0.1683324 ,  0.12936218,  0.16519211, -0.0687213 ,\n",
      "        0.15854927,  0.14995445,  0.15155997,  0.68053364,  0.07293522,\n",
      "       -0.69641424,  0.24290641,  0.01137218, -0.49776516,  0.76082201,\n",
      "       -0.08778058,  0.15307516, -0.07612099, -0.8255196 , -0.10302074,\n",
      "        0.15361171, -0.0028921 , -0.14631916,  0.178823  , -0.34521977,\n",
      "       -0.03228986, -0.22718036,  0.16302561, -0.08703356, -1.41997783,\n",
      "        0.15801178, -0.35185638, -0.18778021, -0.52128843, -0.67809968,\n",
      "        0.11234965, -0.40307363,  0.16386621,  0.29792495,  0.166463  ,\n",
      "       -0.35609979, -0.67296637, -0.06104243,  0.16053492, -0.32894816,\n",
      "       -0.49334568, -0.01250672, -0.51528968,  0.0670246 ,  0.15441098,\n",
      "        0.26077412,  0.05471396,  0.14863664,  0.16166402,  0.12866943,\n",
      "        0.4268591 ,  0.0720129 ])\n",
      " message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     jac: array([-0.0000164 , -0.00134648, -0.00001606, -0.00001583,  0.00676101,\n",
      "       -0.00001453, -0.00001637,  0.00038343, -0.00001508, -0.00001609,\n",
      "       -0.00001586, -0.00001607,  0.00312765, -0.00001599,  0.00277411,\n",
      "        0.00179072, -0.00001554,  0.00897341,  0.00021099,  0.00638926,\n",
      "        0.00562605, -0.00001629,  0.00026938,  0.00188177,  0.00340585,\n",
      "        0.00377389,  0.00365701, -0.00001565, -0.00001521,  0.00898129,\n",
      "        0.00078451, -0.00001483, -0.00001624, -0.00001582,  0.00171367,\n",
      "        0.00148172,  0.00046476,  0.00786928,  0.00560966,  0.00381715,\n",
      "       -0.0000159 ,  0.00613439, -0.00001585, -0.00001571,  0.00316346,\n",
      "       -0.00001521, -0.00001581,  0.00822505,  0.00650267, -0.00001568,\n",
      "       -0.00001543, -0.00001536, -0.0009806 ,  0.00673095,  0.00055726,\n",
      "        0.00069548,  0.00009293,  0.00134775,  0.0018241 , -0.00001593,\n",
      "        0.00699326, -0.00001595, -0.00012624,  0.00336662, -0.00001505,\n",
      "       -0.00001535,  0.00332201,  0.00752541,  0.00583191,  0.00232286,\n",
      "        0.00812762,  0.00867679, -0.00001595,  0.00026677,  0.00015122,\n",
      "        0.00866666,  0.00076737,  0.00711352,  0.00450822, -0.00001513,\n",
      "        0.0079594 , -0.00001561, -0.0007687 ,  0.00261921, -0.00001667,\n",
      "        0.00076688,  0.00175217, -0.00001571, -0.00001541,  0.0049564 ,\n",
      "        0.00361263, -0.00001627,  0.00094193, -0.00001577,  0.00174278,\n",
      "       -0.000016  ,  0.00077536,  0.0019725 , -0.00001586,  0.00243556,\n",
      "        0.00111194,  0.00246145,  0.00216827,  0.00625342,  0.00648777,\n",
      "       -0.00001553,  0.00239997, -0.00001598,  0.00308272,  0.01099683,\n",
      "        0.00487158,  0.00747768,  0.00126858, -0.00001524, -0.00001557,\n",
      "       -0.00001609,  0.00193581,  0.01054304,  0.00054993,  0.00704488,\n",
      "        0.00443167,  0.00486184,  0.0036651 , -0.00001553,  0.00081819,\n",
      "        0.00550427,  0.00217282,  0.00832192, -0.00001616, -0.00001518,\n",
      "       -0.00001543, -0.00001569,  0.00139013,  0.00483959, -0.0000157 ,\n",
      "        0.00014882, -0.00054182,  0.00111525,  0.00650507,  0.00415497,\n",
      "       -0.00001598,  0.00296171, -0.00001617,  0.00188109, -0.00001572,\n",
      "       -0.00001517, -0.00001554,  0.00916456,  0.00770444, -0.0007298 ,\n",
      "        0.00407864,  0.00382211,  0.00019132,  0.00386029,  0.00011107,\n",
      "       -0.00001551,  0.00135444,  0.0051039 ,  0.00019582, -0.00001484,\n",
      "        0.00274845,  0.0012362 ,  0.00081008,  0.00313726,  0.00604673,\n",
      "        0.00733652, -0.00001519,  0.00230907,  0.00443842, -0.00001569,\n",
      "        0.00044055,  0.00138214,  0.00285077,  0.00517889,  0.00145199,\n",
      "        0.00620681, -0.00001584,  0.00596616, -0.00001687,  0.00718815,\n",
      "        0.0073431 ,  0.00647563, -0.00001537,  0.00140052,  0.00102028,\n",
      "        0.00172737,  0.0047259 ,  0.00085824, -0.00001639,  0.00755327,\n",
      "        0.00719729,  0.00021743, -0.00001593,  0.00435589,  0.00443255,\n",
      "        0.00307634,  0.00001686,  0.00134595,  0.00001611,  0.00001634,\n",
      "       -0.00676048,  0.00001589,  0.00001497, -0.00038431,  0.00001555,\n",
      "        0.00001589,  0.00001621,  0.00001491, -0.003127  ,  0.00001503,\n",
      "       -0.00277428, -0.0017903 ,  0.00001565, -0.00897326, -0.00021039,\n",
      "       -0.00638968, -0.00562593,  0.00001573, -0.00026839, -0.00188042,\n",
      "       -0.0034053 , -0.00377423, -0.00365652,  0.00001717,  0.00001532,\n",
      "       -0.00898049, -0.00078571,  0.00001597,  0.00001515,  0.00001574,\n",
      "       -0.00171401, -0.00148199, -0.00046394, -0.00786969, -0.00560948,\n",
      "       -0.00381711,  0.00001496, -0.00613452,  0.00001502,  0.00001572,\n",
      "       -0.0031641 ,  0.00001587,  0.00001579, -0.00822439, -0.00650237,\n",
      "        0.00001593,  0.00001478,  0.00001604,  0.00097959, -0.00673091,\n",
      "       -0.0005569 , -0.00069638, -0.00009344, -0.00134714, -0.00182347,\n",
      "        0.00001558, -0.00699361,  0.00001562,  0.00012688, -0.00336683,\n",
      "        0.00001657,  0.00001559, -0.00332062, -0.00752434, -0.00583085,\n",
      "       -0.00232314, -0.00812667, -0.00867771,  0.00001593, -0.00026697,\n",
      "       -0.00015201, -0.00866714, -0.00076883, -0.00711278, -0.0045079 ,\n",
      "        0.00001643, -0.00795861,  0.00001563,  0.00076806, -0.00261956,\n",
      "        0.00001532, -0.00076685, -0.00175115,  0.00001636,  0.0000163 ,\n",
      "       -0.00495539, -0.00361303,  0.00001541, -0.00094206,  0.00001696,\n",
      "       -0.00174305,  0.00001599, -0.00077571, -0.00197209,  0.00001531,\n",
      "       -0.00243502, -0.00111239, -0.00246107, -0.00216793, -0.0062534 ,\n",
      "       -0.0064886 ,  0.00001548, -0.00239999,  0.00001593, -0.00308229,\n",
      "       -0.01099637, -0.00487054, -0.00747823, -0.00126963,  0.00001611,\n",
      "        0.00001506,  0.00001622, -0.00193518, -0.01054257, -0.0005504 ,\n",
      "       -0.00704449, -0.00443157, -0.00486192, -0.00366515,  0.00001491,\n",
      "       -0.0008199 , -0.00550385, -0.0021719 , -0.00832036,  0.0000155 ,\n",
      "        0.00001526,  0.00001564,  0.00001545, -0.00139019, -0.00484068,\n",
      "        0.00001539, -0.00014904,  0.00054122, -0.00111731, -0.00650327,\n",
      "       -0.00415451,  0.00001683, -0.00296314,  0.00001652, -0.00188077,\n",
      "        0.00001585,  0.000015  ,  0.00001516, -0.00916368, -0.0077038 ,\n",
      "        0.00073016, -0.00407743, -0.00382307, -0.00019223, -0.00386078,\n",
      "       -0.00011146,  0.00001531, -0.00135398, -0.00510462, -0.00019456,\n",
      "        0.00001536, -0.00274685, -0.00123691, -0.00081002, -0.00313876,\n",
      "       -0.00604857, -0.00733647,  0.0000163 , -0.00230961, -0.00443781,\n",
      "        0.0000158 , -0.00044139, -0.00138243, -0.00284933, -0.005179  ,\n",
      "       -0.00145248, -0.0062068 ,  0.00001639, -0.0059667 ,  0.00001665,\n",
      "       -0.00718783, -0.00734198, -0.00647456,  0.00001605, -0.00140073,\n",
      "       -0.00101998, -0.00172622, -0.00472535, -0.00085869,  0.00001544,\n",
      "       -0.00755165, -0.00719501, -0.00021815,  0.00001617, -0.00435557,\n",
      "       -0.00443326, -0.0030767 ])\n",
      "     nit: 227\n"
     ]
    }
   ],
   "source": [
    "##======================================================================\n",
    "## STEP 4: Train the softmax classifier\n",
    "\n",
    "lambda_ = 1e-4\n",
    "options_ = {'maxiter': tot_iter, 'disp': True}\n",
    "\n",
    "opt_theta, input_size, num_classes = softmax.softmax_train(hidden_size, num_labels,\n",
    "                                                           lambda_, train_features,\n",
    "                                                           train_labels, options_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.94%\n"
     ]
    }
   ],
   "source": [
    "##======================================================================\n",
    "## STEP 5: Testing\n",
    "\n",
    "predictions, pred_prob = softmax.softmax_predict((opt_theta, input_size, num_classes), test_features)\n",
    "print \"Accuracy: {0:.2f}%\".format(100 * np.sum(predictions == test_labels, dtype=np.float64) / test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3654, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3318   84]\n",
      " [ 101  151]]\n"
     ]
    }
   ],
   "source": [
    "Y_preds_sae = predictions\n",
    "conf = metrics.confusion_matrix(y_test,Y_preds_sae)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.97      0.98      0.97      3402\n",
      "    class 1       0.64      0.60      0.62       252\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, Y_preds_sae, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_preds_sae==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96868244,  0.03131756],\n",
       "       [ 0.96235483,  0.03764517],\n",
       "       [ 0.98740001,  0.01259999],\n",
       "       ..., \n",
       "       [ 0.94299153,  0.05700847],\n",
       "       [ 0.99951257,  0.00048743],\n",
       "       [ 0.99797109,  0.00202891]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96868244  0.03131756]\n",
      " [ 0.96235483  0.03764517]\n",
      " [ 0.98740001  0.01259999]\n",
      " [ 0.99904941  0.00095059]\n",
      " [ 0.88018202  0.11981798]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEeCAYAAACUiVJFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIi0tv8DPj5Hs612yhsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23be7d7310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_preds_prob_sae = pred_prob#model.predict_proba(X_test_1, verbose=0)\n",
    "print(Y_preds_prob_sae[:5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ROC curve\n",
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr1, tpr1, thresholds = metrics.roc_curve(y_test, Y_preds_prob_sae[:,1])\n",
    "plt.plot(fpr1, tpr1, lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve',fontsize=14)\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)',fontsize=14) #fontweight='bold'\n",
    "plt.ylabel('True Positive Rate (Sensitivity)',fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "#plt.savefig('smartgrid_sae_roc.png')\n",
    "\n",
    "#Y_logPred_prob = logReg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824117232627\n"
     ]
    }
   ],
   "source": [
    "print metrics.roc_auc_score(y_test, Y_preds_prob_sae[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DO NOT RUN DO NOT RUN DO NOT RUN DO NOT RUN\n",
    "\n",
    "import load_MNIST\n",
    "import numpy as np\n",
    "import sparse_autoencoder\n",
    "import scipy.optimize\n",
    "import display_network\n",
    "import softmax\n",
    "\n",
    "## ======================================================================\n",
    "#  STEP 0: Here we provide the relevant parameters values that will\n",
    "#  allow your sparse autoencoder to get good filters;\n",
    "\n",
    "input_size = 28 * 28\n",
    "num_labels = 5\n",
    "hidden_size = 196\n",
    "\n",
    "sparsity_param = 0.1  # desired average activation of the hidden units.\n",
    "lambda_ = 3e-3  # weight decay parameter\n",
    "beta = 3  # weight of sparsity penalty term\n",
    "\n",
    "## ======================================================================\n",
    "#  STEP 1: Load data from the MNIST database\n",
    "#\n",
    "#  This loads our training and test data from the MNIST database files.\n",
    "#  \n",
    "\n",
    "images = load_MNIST.load_MNIST_images('train-images-idx3-ubyte')\n",
    "labels = load_MNIST.load_MNIST_labels('train-labels-idx1-ubyte')\n",
    "\n",
    "unlabeled_index = np.argwhere(labels >= 5).flatten()  #5,6,7,8,9,10 unlabeled\n",
    "labeled_index = np.argwhere(labels < 5).flatten()     #0,1,2,3,4 labeled\n",
    "\n",
    "num_train = round(labeled_index.shape[0] / 2)\n",
    "train_index = labeled_index[0:num_train]\n",
    "test_index = labeled_index[num_train:]\n",
    "\n",
    "unlabeled_data = images[:, unlabeled_index]\n",
    "\n",
    "train_data = images[:, train_index]\n",
    "train_labels = labels[train_index]\n",
    "\n",
    "test_data = images[:, test_index]\n",
    "test_labels = labels[test_index]\n",
    "\n",
    "print '# examples in unlabeled set: {0:d}\\n'.format(unlabeled_data.shape[1])\n",
    "print '# examples in supervised training set: {0:d}\\n'.format(train_data.shape[1])\n",
    "print '# examples in supervised testing set: {0:d}\\n'.format(test_data.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
