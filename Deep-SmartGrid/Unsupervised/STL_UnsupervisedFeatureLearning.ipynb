{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Self-Taught Learning and Unsupervised Feature Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import load_MNIST\n",
    "import numpy as np\n",
    "import sparse_autoencoder\n",
    "import scipy.optimize\n",
    "import display_network\n",
    "import softmax\n",
    "\n",
    "## ======================================================================\n",
    "#  STEP 0: Here we provide the relevant parameters values that will\n",
    "#  allow your sparse autoencoder to get good filters; you do not need to\n",
    "#  change the parameters below.\n",
    "\n",
    "input_size = 28 * 28\n",
    "num_labels = 5\n",
    "hidden_size = 196\n",
    "\n",
    "sparsity_param = 0.1  # desired average activation of the hidden units.\n",
    "lambda_ = 3e-3  # weight decay parameter\n",
    "beta = 3  # weight of sparsity penalty term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load_MNIST.py:18: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  images = images.reshape((num_images, num_rows * num_cols)).transpose()\n"
     ]
    }
   ],
   "source": [
    "## ======================================================================\n",
    "#  STEP 1: Load data from the MNIST database\n",
    "#\n",
    "#  This loads our training and test data from the MNIST database files.\n",
    "#  We have sorted the data for you in this so that you will not have to\n",
    "#  change it.\n",
    "\n",
    "images = load_MNIST.load_MNIST_images('train-images-idx3-ubyte')\n",
    "labels = load_MNIST.load_MNIST_labels('train-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# examples in unlabeled set: 29404\n",
      "\n",
      "# examples in supervised training set: 15298\n",
      "\n",
      "# examples in supervised testing set: 15298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:6: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "unlabeled_index = np.argwhere(labels >= 5).flatten()\n",
    "labeled_index = np.argwhere(labels < 5).flatten()\n",
    "\n",
    "num_train = round(labeled_index.shape[0] / 2)\n",
    "train_index = labeled_index[0:num_train]\n",
    "test_index = labeled_index[num_train:]\n",
    "\n",
    "unlabeled_data = images[:, unlabeled_index]\n",
    "\n",
    "train_data = images[:, train_index]\n",
    "train_labels = labels[train_index]\n",
    "\n",
    "test_data = images[:, test_index]\n",
    "test_labels = labels[test_index]\n",
    "\n",
    "print '# examples in unlabeled set: {0:d}\\n'.format(unlabeled_data.shape[1])\n",
    "print '# examples in supervised training set: {0:d}\\n'.format(train_data.shape[1])\n",
    "print '# examples in supervised testing set: {0:d}\\n'.format(test_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15298,)\n",
      "784 196\n",
      "(784, 60000)\n",
      "28.0\n"
     ]
    }
   ],
   "source": [
    "print train_labels.shape\n",
    "print input_size, hidden_size\n",
    "print images.shape\n",
    "print np.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ======================================================================\n",
    "#  STEP 2: Train the sparse autoencoder\n",
    "#  This trains the sparse autoencoder on the unlabeled training\n",
    "#  images.\n",
    "\n",
    "#  Randomly initialize the parameters\n",
    "theta = sparse_autoencoder.initialize(hidden_size, input_size)\n",
    "\n",
    "J = lambda x: sparse_autoencoder.sparse_autoencoder_cost(x, input_size, hidden_size,\n",
    "                                                         lambda_, sparsity_param,\n",
    "                                                         beta, unlabeled_data)\n",
    "\n",
    "options_ = {'maxiter': 400, 'disp': True}\n",
    "result = scipy.optimize.minimize(J, theta, method='L-BFGS-B', jac=True, options=options_)\n",
    "opt_theta = result.x\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the weights\n",
    "W1 = opt_theta[0:hidden_size * input_size].reshape(hidden_size, input_size).transpose()\n",
    "display_network.display_network(W1,filename='STL_Weights.png')\n",
    "\n",
    "##======================================================================\n",
    "## STEP 3: Extract Features from the Supervised Dataset\n",
    "#\n",
    "#  You need to complete the code in feedForwardAutoencoder.m so that the\n",
    "#  following command will extract features from the data.\n",
    "\n",
    "train_features = sparse_autoencoder.sparse_autoencoder(opt_theta, hidden_size,\n",
    "                                                       input_size, train_data)\n",
    "\n",
    "test_features = sparse_autoencoder.sparse_autoencoder(opt_theta, hidden_size,\n",
    "                                                      input_size, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##======================================================================\n",
    "## STEP 4: Train the softmax classifier\n",
    "\n",
    "lambda_ = 1e-4\n",
    "options_ = {'maxiter': 400, 'disp': True}\n",
    "\n",
    "opt_theta, input_size, num_classes = softmax.softmax_train(hidden_size, num_labels,\n",
    "                                                           lambda_, train_features,\n",
    "                                                           train_labels, options_)\n",
    "\n",
    "##======================================================================\n",
    "## STEP 5: Testing\n",
    "\n",
    "predictions = softmax.softmax_predict((opt_theta, input_size, num_classes), test_features)\n",
    "print \"Accuracy: {0:.2f}%\".format(100 * np.sum(predictions == test_labels, dtype=np.float64) / test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
